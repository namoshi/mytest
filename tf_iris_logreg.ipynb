{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf_iris_logreg.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/namoshi/mytest/blob/master/tf_iris_logreg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "9L3NMFhv_ghS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "50edb094-69e7-4eb7-ee53-fd9d815f76b7"
      },
      "cell_type": "code",
      "source": [
        "#\n",
        "#   iris_lr_softmax.py\n",
        "#       date. 5/6/2016\n",
        "#       IRIS data set classification\n",
        "#\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn import datasets\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def prep_data(train_siz=120, test_siz=30):\n",
        "    '''\n",
        "      class: \n",
        "        1. Iris Setosa, 2. Iris Versicolor, 3. Iris Virginica\n",
        "    '''\n",
        "#    cols = ['sepal_len', 'sepal_wid', 'petal_len', 'petal_wid', 'class']  \n",
        "#    iris_df = pd.read_csv('./iris.csv', header=True, names=cols)\n",
        "    \n",
        "    # Encode class \n",
        "    class_name = ['setosa', 'versicolor', 'virginica']\n",
        "#    iris_df['iclass'] = [class_name.index(class_str) \n",
        "#                            for class_str in iris_df['class'].values]\n",
        "  \n",
        "    iris = datasets.load_iris()\n",
        "    \n",
        "    iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "    iris_df['target'] = iris.target_names[iris.target]\n",
        "    iris_df.head()\n",
        "    \n",
        "    # Random Shuffle before split to train/test\n",
        "    data_len = len(iris_df)\n",
        "    orig = np.arange(data_len)\n",
        "    perm = np.copy(orig)\n",
        "    np.random.shuffle(perm)\n",
        "    iris=iris_df[['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)', 'target']].values\n",
        "    iris[orig, :] = iris[perm, :]\n",
        "    \n",
        "    # generate onehot label data\n",
        "    label = np.zeros((data_len, 3), dtype=np.float32)\n",
        "    for i in range(data_len):\n",
        "      for iclass in range(3):\n",
        "#        print('i=', i, 'iclass=', iclass, 'iris[i, -1]=',iris[i, -1])\n",
        "        if (iris[i, -1] == class_name[iclass]):\n",
        "          label[i, iclass] = 1.0\n",
        "#      print(label[i])\n",
        "#    print(label)\n",
        "    \n",
        "    # Split dataset\n",
        "    trX = iris[:train_siz, :-1]\n",
        "    teX = iris[train_siz:, :-1]\n",
        "    trY = label[:train_siz, :]\n",
        "    teY = label[train_siz:, :]\n",
        "    \n",
        "    return trX, trY, teX, teY\n",
        "    \n",
        "def linear_model(X, w, b):\n",
        "    output = tf.matmul(X, w) + b\n",
        "\n",
        "    return output\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    tr_x, tr_y, te_x, te_y = prep_data()\n",
        "\n",
        "    # Variables\n",
        "    x = tf.placeholder(tf.float32, [None, 4])\n",
        "    y_ = tf.placeholder(tf.float32, [None, 3])\n",
        "    \n",
        "    w = tf.Variable(tf.random_normal([4, 3], mean=0.0, stddev=0.005))\n",
        "    b = tf.Variable(tf.zeros([3]))\n",
        "\n",
        "    y_pred = linear_model(x, w, b)\n",
        "    y_pred_softmax = tf.nn.softmax(y_pred)   # for prediction\n",
        "\n",
        "    loss = -tf.reduce_sum(y_*tf.log(y_pred_softmax))\n",
        "    train_step = tf.train.GradientDescentOptimizer(0.001).minimize(loss)\n",
        "\n",
        "    correct_prediction = tf.equal(tf.argmax(y_pred_softmax, 1), \n",
        "        tf.argmax(y_, 1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "    # Train\n",
        "    init = tf.global_variables_initializer()\n",
        "\n",
        "    with tf.Session() as sess:\n",
        "        sess.run(init)\n",
        "\n",
        "        print('Training...')\n",
        "        for i in range(10001):\n",
        "            batch_xs, batch_ys = tr_x, tr_y\n",
        "            train_step.run({x: batch_xs, y_: batch_ys})                 \n",
        "        \n",
        "            if i % 1000 == 0:\n",
        "                fd_train = {x: batch_xs, y_: batch_ys}\n",
        "                loss_step = loss.eval(fd_train)\n",
        "                train_accuracy = accuracy.eval(fd_train)\n",
        "                print('  step, loss, accurary = %6d: %8.3f,%8.3f' % (i, \n",
        "                                                loss_step, train_accuracy))\n",
        "        \n",
        "        # Test trained model\n",
        "        fd_test = {x: te_x, y_: te_y}\n",
        "        print('accuracy = %10.4f' % accuracy.eval(fd_test))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training...\n",
            "  step, loss, accurary =      0:  123.860,   0.333\n",
            "  step, loss, accurary =   1000:   13.887,   0.983\n",
            "  step, loss, accurary =   2000:   10.767,   0.983\n",
            "  step, loss, accurary =   3000:    9.494,   0.992\n",
            "  step, loss, accurary =   4000:    8.776,   0.992\n",
            "  step, loss, accurary =   5000:    8.304,   0.992\n",
            "  step, loss, accurary =   6000:    7.964,   0.992\n",
            "  step, loss, accurary =   7000:    7.704,   0.992\n",
            "  step, loss, accurary =   8000:    7.496,   0.992\n",
            "  step, loss, accurary =   9000:    7.325,   0.992\n",
            "  step, loss, accurary =  10000:    7.180,   0.992\n",
            "accuracy =     0.9667\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}